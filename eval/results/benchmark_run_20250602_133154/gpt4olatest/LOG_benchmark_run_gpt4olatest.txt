2025-06-02 13:31:56,196 [INFO] concord.llm.prompts: Loaded template: v2
2025-06-02 13:31:56,197 [INFO] concord.llm.prompts: Loaded template: v2.1
2025-06-02 13:31:56,197 [INFO] concord.llm.prompts: Loaded template: v3.0-CoT
2025-06-02 13:31:56,197 [INFO] concord.llm.prompts: Loaded template: v3.1-CoT
2025-06-02 13:31:56,197 [INFO] concord.llm.prompts: Loaded template: v3.2
2025-06-02 13:31:56,197 [INFO] concord.llm.prompts: Loaded template: v1.0
2025-06-02 13:31:56,197 [INFO] concord.llm.prompts: Loaded template: v3.0
2025-06-02 13:31:56,197 [INFO] concord.llm.prompts: Loaded template: v3.1
2025-06-02 13:31:56,197 [INFO] concord.llm.prompts: Loaded template: v3.2-CoT
2025-06-02 13:31:56,201 [INFO] concord.llm.argo_gateway: ArgoGatewayClient initialised | model=gpt4olatest env=prod timeout=30.0s url=https://apps.inside.anl.gov/argoapi/api/v1/resource/chat/
✓ Gateway reachable
Processing:   0%|          | 0/23 [00:00<?, ?row/s]2025-06-02 13:31:56,735 [INFO] concord.llm.argo_gateway: ArgoGatewayClient initialised | model=gpt4olatest env=prod timeout=30.0s url=https://apps.inside.anl.gov/argoapi/api/v1/resource/chat/
2025-06-02 13:31:56,784 [INFO] concord.llm.argo_gateway: ArgoGatewayClient initialised | model=gpt4olatest env=prod timeout=30.0s url=https://apps.inside.anl.gov/argoapi/api/v1/resource/chat/
Processing:  87%|████████▋ | 20/23 [00:05<00:00,  3.86row/s]2025-06-02 13:32:01,917 [INFO] concord.llm.argo_gateway: ArgoGatewayClient initialised | model=gpt4olatest env=prod timeout=30.0s url=https://apps.inside.anl.gov/argoapi/api/v1/resource/chat/
Processing: 100%|██████████| 23/23 [00:07<00:00,  2.82row/s]Processing: 100%|██████████| 23/23 [00:07<00:00,  3.03row/s]
2025-06-02 13:32:04,315 [INFO] concord.pipeline: Processed 23 rows in 7.61s
✓ Output written to eval/results/benchmark_run_20250602_133154/gpt4olatest/gpt4olatest_v3.2_zero.csv
2025-06-02 13:32:04,316 [INFO] concord.embedding: Embedding cache cleared
2025-06-02 13:32:06,251 [INFO] concord.llm.prompts: Loaded template: v2
2025-06-02 13:32:06,251 [INFO] concord.llm.prompts: Loaded template: v2.1
2025-06-02 13:32:06,251 [INFO] concord.llm.prompts: Loaded template: v3.0-CoT
2025-06-02 13:32:06,251 [INFO] concord.llm.prompts: Loaded template: v3.1-CoT
2025-06-02 13:32:06,251 [INFO] concord.llm.prompts: Loaded template: v3.2
2025-06-02 13:32:06,251 [INFO] concord.llm.prompts: Loaded template: v1.0
2025-06-02 13:32:06,251 [INFO] concord.llm.prompts: Loaded template: v3.0
2025-06-02 13:32:06,251 [INFO] concord.llm.prompts: Loaded template: v3.1
2025-06-02 13:32:06,251 [INFO] concord.llm.prompts: Loaded template: v3.2-CoT
2025-06-02 13:32:06,255 [INFO] concord.llm.argo_gateway: ArgoGatewayClient initialised | model=gpt4olatest env=prod timeout=30.0s url=https://apps.inside.anl.gov/argoapi/api/v1/resource/chat/
2025-06-02 13:32:36,337 [WARNING] concord.llm.argo_gateway: Timeout on attempt 1
[retry 1/5] timeout; sleeping 1.5s
✓ Gateway reachable
Processing:   0%|          | 0/23 [00:00<?, ?row/s]2025-06-02 13:32:38,398 [INFO] concord.llm.argo_gateway: ArgoGatewayClient initialised | model=gpt4olatest env=prod timeout=30.0s url=https://apps.inside.anl.gov/argoapi/api/v1/resource/chat/
2025-06-02 13:32:38,444 [INFO] concord.llm.argo_gateway: ArgoGatewayClient initialised | model=gpt4olatest env=prod timeout=30.0s url=https://apps.inside.anl.gov/argoapi/api/v1/resource/chat/
Processing:  87%|████████▋ | 20/23 [00:07<00:01,  2.75row/s]2025-06-02 13:32:45,666 [INFO] concord.llm.argo_gateway: ArgoGatewayClient initialised | model=gpt4olatest env=prod timeout=30.0s url=https://apps.inside.anl.gov/argoapi/api/v1/resource/chat/
Processing: 100%|██████████| 23/23 [00:10<00:00,  2.14row/s]Processing: 100%|██████████| 23/23 [00:10<00:00,  2.27row/s]
2025-06-02 13:32:48,532 [INFO] concord.pipeline: Processed 23 rows in 10.16s
✓ Output written to eval/results/benchmark_run_20250602_133154/gpt4olatest/gpt4olatest_v3.2-CoT_zero.csv
2025-06-02 13:32:48,537 [INFO] concord.embedding: Embedding cache cleared
[1/2] Running MODE=zero-shot, PROMPT=v3.2, SIM_HINT=no -> eval/results/benchmark_run_20250602_133154/gpt4olatest/gpt4olatest_v3.2_zero.csv
[2/2] Running MODE=zero-shot, PROMPT=v3.2-CoT, SIM_HINT=no -> eval/results/benchmark_run_20250602_133154/gpt4olatest/gpt4olatest_v3.2-CoT_zero.csv
