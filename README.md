# CONCORDIA  
*CONcordance of Curated & Original Raw Descriptions In Annotations*

Concordia compares two functionalâ€‘annotation sourcesâ€”old vsâ€¯new, RAST vsâ€¯UniProt, manual vsâ€¯AIâ€”and writes a tidy table that contains  

* **`similarity_Pubmedbert`** â€“ cosine similarity from the PubMedBERT sentenceâ€‘embedding model  
* **`label`** â€“ a oneâ€‘word judgement from an LLM (`o3â€‘mini` by default) drawn from a sevenâ€‘class ontology  
* **`note`** â€“ the LLMâ€™s superâ€‘short reason (blank if the heuristic label is used)

---

## Installation
```bash
git clone https://github.com/you/concordia.git
cd concordia
poetry install          # dependencies + CLI
poetry shell            # activate venv
```

---

## Quickâ€‘start recipes

| Purpose | Command |
|---------|---------|
| CSV with **default LLM** (o3â€‘mini â†’ appsâ€‘dev) | `concord example_data/annotations_test.csv` |
| TSV with **GPTâ€‘4o** (appsâ€‘prod) | `concord example_data/annotations_test.tsv --llm-model gpt4o` |
| **Embedâ€‘only** (no LLM) | `concord â€¦csv --mode local` |
| **Dual** (embed **and** LLM) | `concord â€¦csv --mode dual` |
| Two adâ€‘hoc strings | `concord --text-a "RecA" --text-b "DNA recombinaseÂ A"` |

---

## Accepted input formats

| Extension | Loader | Note |
|-----------|--------|------|
| `.csv` | `pandas.read_csv(sep=',')` | default |
| `.tsv`Â /Â `.tab` | `pandas.read_csv(sep='\t')` | or `--sep "\t"` |
| `.json` | `pandas.read_json()` | listâ€‘ofâ€‘objects **or** columnâ€‘orient |

Unless you pass `--col-a / --col-b`, the **first two textual columns that donâ€™t end with `id`** are taken.

---

## Minimal sample CSV
```csv
annotation_a,annotation_b
DNA repair protein RecA,RecombinaseÂ A
Hypothetical protein,Uncharacterized protein
```
Any extra columns (e.g. `gene_id`) are preserved in the output.

---

## CLI options

| Flag | Description |
|------|-------------|
| **`FILE`** | Input table (`.csv`, `.tsv`, `.json`) |
| `--text-a / --text-b` | Compare two strings instead of a file |
| `--mode` | `llm`â€¯(default)â€‚|â€‚`local`â€‚|â€‚`dual` |
| `--llm-model` | Gateway LLM (`gpto3mini`,Â `gpt4o`,Â â€¦) |
| `--retry` | Number of automatic blankâ€‘reply retries (defaultÂ 5) |
| `--output` | Destination path (fileâ€‘mode only) |
| `--cfg` | Alternate YAML config |
| `--col-a / --col-b` | Explicit annotation columns |
| `--sep` | Custom delimiter for text files |

---

## Modes

| Mode | What happens | Extra columns |
|------|--------------|---------------|
| **llm**  | Skip embeddings; every pair â†’Â LLM | `label`,Â `note` |
| **local**| PubMedBERT embeddings â†’ cosine â†’ heuristic label | `similarity_Pubmedbert`,Â `label` |
| **dual** | Embeddings **and** LLM for every row | `similarity_Pubmedbert`,Â `label`,Â `note` |

> **Embedding model**â€‚[`NeuML/pubmedbert-base-embeddings`](https://huggingface.co/NeuML/pubmedbert-base-embeddings)Â (Apacheâ€‘2.0)

---

## 7â€‘label ontology

| Label | Meaning |
|-------|---------|
| **Exact** | Same function; wording/punctuation only |
| **Synonym** | Semantically equivalent paraphrase |
| **Broader** | A âŠƒÂ B (A more general) |
| **Narrower** | A âŠ‚Â B (A more specific) |
| **Related** | Same pathway / complex / family but not parentâ€“child |
| **Uninformative** | Placeholder or extremely generic |
| **Different** | No functional overlap |

### Alias system â€” why you rarely see **Unknown**

Some GPT checkpoints still answer with older words like *Identical* or *Partial*.  
`llm_label()` contains a tiny alias map:

```python
_ALIAS = {"Identical": "Exact",
          "Equivalent": "Synonym",
          "Partial": "Related"}
label = _ALIAS.get(label, label)
```

Any legacy token is transparently remapped, so `Unknown` only appears when the reply is genuinely empty or malformed.

---

## Prompting â€” tweak in one place

All prompt text lives in **`concord/llm/prompts.py`**.  
Edit the fewâ€‘shot examples or definitions to experiment; the rest of the code stays untouched.

---

## Config snapshot (`concord/config.yaml`)
```yaml
engine:
  mode: llm

llm:
  model: gpto3mini        # autoâ€‘routes to appsâ€‘dev
  stream: false
  user: ${ARGO_USER}

local:
  model_id: NeuML/pubmedbert-base-embeddings
```
*(Leave `env` unsetâ€”oâ€‘series â†’ appsâ€‘dev, GPTâ€‘4* â†’ appsâ€‘prod.)*

---

## Progress & recovery

* Output is **appended rowâ€‘byâ€‘row** â€“ Ctrlâ€‘C and rerun, finished pairs are skipped.  
* Live progress bar example:
```
Processing 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 730/1000 [00:14<00:05, 49.2it/s]
```
o3â€‘mini â‰ˆÂ 0.10â€¯s per pair; embeddings â‰ˆÂ 1â€¯ms per string on AppleÂ Mâ€‘series.

---

## FAQ

| Q | A |
|---|---|
| **Why keep similarity in LLM mode?** | Free sanity check (â‰ˆâ€¯2â€¯ms) |
| **Still see â€œUnknownâ€?** | Means reply didnâ€™t start with any known token; tweak alias or prompt |
| **Where are model weights?** | HuggingÂ Face cache (`~/.cache/huggingface`) |
| **Crash recovery?** | Output is appendâ€‘only; rerun resumes automatically |

---

*Happy concording! â€“ StarsÂ â­, issuesÂ ðŸž, and PRsÂ ðŸ’¡ welcome.*
